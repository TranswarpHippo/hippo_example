{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Similarity Search with Hippo and OpenAI\n",
    "\n",
    "This page discusses the integration of a vector database with OpenAI's Embedding API and OpenAI's Chat API.\n",
    "\n",
    "We will showcase how OpenAI's Embedding API can be used with our vector database to turn user questions into Hippo query conditions. Then, by conducting a similarity search, we can find text that can answer the user's question. Next, the user's question and text are concatenated into a prompt, which serves as the input for OpenAI's Chat API. Finally, we receive a response from the Chat API offered by OpenAI.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "The only prerequisite here is an API key from the OpenAI website. Make sure you have already started a Hippo instance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "357f24224a8e818f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "Initially, we require the installation of certain dependencies, such as OpenAI, Langchain, and Hippo-API. Please note, you should install the appropriate versions tailored to your environment."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a92d2ce26df7ac4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install hippo-api\n",
    "!pip install langchain==0.0.220\n",
    "!pip install unstructured==0.9.1\n",
    "!pip install markdown==3.4.4\n",
    "!pip install tiktoken==0.4.0\n",
    "!pip install openai==0.27.8"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13b1d1ae153ff434"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Python version needs to be >=3.8.\n",
    "\n",
    "## Best Practice\n",
    "### Importing Dependency Packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "554081137df2c252"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import re\n",
    "from transwarp_hippo_langchain.hippo_langchain import Hippo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T08:42:17.234673Z",
     "start_time": "2023-09-22T08:42:16.401351Z"
    }
   },
   "id": "5ff3296ce812aeb8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Knowledge Documents"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dad255dae8aea755"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "loader = UnstructuredMarkdownLoader('./content/hippo.md')\n",
    "docs = loader.load()\n",
    "page_content = re.sub(\"[\\n\\r\\t]\", \"\", docs[0].page_content)\n",
    "meta = docs[0].metadata\n",
    "docs = [Document(page_content=page_content, metadata=meta)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T08:42:24.549823Z",
     "start_time": "2023-09-22T08:42:23.916298Z"
    }
   },
   "id": "f02d66a7fd653dc1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Segmenting the Knowledge Document\n",
    "\n",
    "Here, we use Langchain's RecursiveCharacterTextSplitter for segmentation. The delimiter is a period. After segmentation, the text segment does not exceed 2000 characters, and the number of repeated characters is 200."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9b93c330f1c6160"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators='.', chunk_size=2000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T08:42:31.979807Z",
     "start_time": "2023-09-22T08:42:31.951866Z"
    }
   },
   "id": "fe6b43175318331f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Declaring the Embedding Model\n",
    "Below, we create the OpenAI or Azure embedding model using the OpenAIEmbeddings method from Langchain."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eefe28c7c993ffdf"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#openai\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=\"xxx\",\n",
    "                                  model=\"text-embedding-ada-002\")\n",
    "#azure\n",
    "# embeddings = OpenAIEmbeddings(\n",
    "#     openai_api_type=\"azure\",\n",
    "#     openai_api_base=\"x x x\",\n",
    "#     openai_api_version=\"x x x\",\n",
    "#     model=\"x x x\",\n",
    "#     deployment=\"x x x\",\n",
    "#     openai_api_key=\"x x x\"\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T08:42:33.806790Z",
     "start_time": "2023-09-22T08:42:33.772300Z"
    }
   },
   "id": "8619f16b9f7355ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Declaring Hippo Client"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e60235602ed91d3c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "HIPPO_CONNECTION = {\n",
    "    \"host\": \"ip\",\n",
    "    \"port\": \"port\",\n",
    "    \"username\": \"xxx\",\n",
    "    \"password\": \"xxx\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T08:42:36.986032Z",
     "start_time": "2023-09-22T08:42:36.980525Z"
    }
   },
   "id": "c666b70dcab78129"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Storing the Document"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43ee6dbd765c3172"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"input...\")\n",
    "\n",
    "# insert docs\n",
    "vector_store = Hippo.from_documents(\n",
    "    docs,\n",
    "    embedding=embeddings,\n",
    "    table_name=\"knowledge_qa\",\n",
    "    connection_args=HIPPO_CONNECTION\n",
    ")\n",
    "print(\"success\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79372c869844bdc9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conducting Knowledge-based Question and Answer\n",
    "#### Creating a Large Language Question-Answering Model\n",
    "Below, we create the OpenAI or Azure large language question-answering model respectively using the AzureChatOpenAI and ChatOpenAI methods from Langchain."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89077cc9763d5dd0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# llm = AzureChatOpenAI(\n",
    "#     openai_api_base=\"x x x\",\n",
    "#     openai_api_version=\"xxx\",\n",
    "#     deployment_name=\"xxx\",\n",
    "#     openai_api_key=\"xxx\",\n",
    "#     openai_api_type=\"azure\"\n",
    "# )\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"xxx\",\n",
    "    model_name=\"gpt-3.5-turbo-16k\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T08:42:58.379925Z",
     "start_time": "2023-09-22T08:42:58.375609Z"
    }
   },
   "id": "c9f2c42e9884f628"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Acquiring Related Knowledge Based on the Questionï¼š"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4c5d73016a9db0c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "query = \"Please introduce hippo\"\n",
    "# query = \"Please introduce Hippo Core Architecture\"\n",
    "# query = \"What operations does the Hippo Vector Database support for vector data?\"\n",
    "# query = \"Does Hippo use hardware acceleration technology? Briefly introduce hardware acceleration technology.\"\n",
    "\n",
    "\n",
    "# Retrieve similar content from the knowledge base,fetch the top two most similar texts.\n",
    "res = vector_store.similarity_search(query, 2)\n",
    "content_list = [item.page_content for item in res]\n",
    "text = ''.join(content_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T08:46:11.245229Z",
     "start_time": "2023-09-22T08:46:04.205901Z"
    }
   },
   "id": "8656e80519da1f97"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constructing a Prompt Template"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5adbaaa7086d1ae"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Please use the content of the following [Article] to answer my question. If you don't know, please say you don't know, and the answer should be concise.\"\n",
    "[Article]:{text}\n",
    "Please answer this question in conjunction with the above article:{query}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T08:46:11.257086Z",
     "start_time": "2023-09-22T08:46:11.249065Z"
    }
   },
   "id": "b915d3001a2741c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Waiting for the Large Language Model to Generate an Answer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b36b6a9adbec8a82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response_with_hippo = llm.predict(prompt)\n",
    "print(f\"response_with_hippo:{response_with_hippo}\")\n",
    "response_without_hippo = llm.predict(query)\n",
    "print(\"==========================================\")\n",
    "print(f\"response_without_hippo:{response_without_hippo}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58eb5d2396321001"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
